# Implementation adapted from Chang, T. A., Tu, Z., & Bergen, B. K. (2022). 
# The geometry of multilingual language model representations. arXiv preprint arXiv:2205.10964.
# https://github.com/tylerachang/multilingual-geometry

"""
Extracts token representations, using examples from pickled_subsets_dir
(generated by subset_examples.py, see readme). Outputs an npy tensor
(shape: num_tokens x hidden_size) for each language.

python3 extract_representations.py --model_name_or_path="xlm-roberta-base" \
--per_device_eval_batch_size=8 --max_seq_length 512 --cache_dir="../hf_cache" \
--pickled_subsets_dir="../oscar_xlmr_tokenized_subsets/for_visualizations" \
--output_dir="../oscar_xlmr_reps" \
--layer=8 --langs ar en es zh ru

"""

import os
import argparse
import numpy as np
import torch
import codecs
import pickle
from transformers import (
    AutoConfig,
    AutoTokenizer,
    AutoModelForMaskedLM,
    AutoModelForCausalLM
)
from src.normalize import *
from src.utils import get_hidden_states
import csv
from scipy.linalg import svd

def create_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_name_or_path', type=str)
    parser.add_argument("--data", type=str, help="Path to file to get sentences")
    parser.add_argument('--output_dir', type=str)
    parser.add_argument("--src_lang_code", type=str, default='spa_Latn', help="Source language code")
    return parser

def get_hidden_states(prompt, tokenizer, model):
    # Encode input context
    input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(model.device)
    # Run model and get output including hidden states
    with torch.no_grad():  # Disabling gradient calculation for inference
        output = model(input_ids, output_hidden_states=True)
    # Extract hidden states
    hidden_states = output.hidden_states
    return hidden_states, input_ids.cpu() 
    #return None, input_ids.cpu()

def get_subspace(hidden_states, output_dir, layer):
    rep_mean = np.mean(hidden_states, axis=0)
    print("Running SVD on {} token representations...".format(hidden_states.shape[0]))
    hidden_states = hidden_states - rep_mean.reshape(1, -1)
    # Assume num_tokens > dim_size.
    # Shapes: (num_tokens x num_tokens), (dim_size), (dim_size x dim_size).
    # Note: rows of vh form the orthonormal basis, corresponding to the singular
    # values in s.
    # Note: do not output full matrices because u would have shape (num_tokens x num_tokens)
    # instead of num_tokens x dim_size (much smaller in memory).
    u, s, vh = svd(hidden_states, full_matrices=False, compute_uv=True, overwrite_a=True)
    s_outpath = os.path.join(output_dir, "{}_s.npy".format(layer))
    vh_outpath = os.path.join(output_dir, "{}_vh.npy".format(layer))
    mean_outpath = os.path.join(output_dir, "{}_mean.npy".format(layer))
    np.save(s_outpath, s, allow_pickle=False)
    np.save(vh_outpath, vh, allow_pickle=False)
    np.save(mean_outpath, rep_mean, allow_pickle=False)
    print("Saved computed subspace.")
    return s, vh, rep_mean

TGTS=['spa_Latn', 'eng_Latn', 'fra_Latn', 'ita_Latn', 'cat_Latn', 'por_Latn', 'deu_Latn', 'eus_Latn', 'glg_Latn']
MAX_SENTENCES = 300
def main(args):
    # Load tokenizer
    print("Loading tokenizer...")
    tokenizer_kwargs = {
        "unk_token": '<unk>',
        "pad_token": '<pad>',
        "model_max_length": 2048,
        "trust_remote_code": True
    }
    tokenizer = AutoTokenizer.from_pretrained( args.model_name_or_path, **tokenizer_kwargs)

    print("Loading model")
    model = AutoModelForCausalLM.from_pretrained(args.model_name_or_path)
    model.cuda()
    print('Model loaded')
    print(model.device)

    csv_file_path = os.path.join(args.output_dir, "input_ids.csv")
    with open(csv_file_path, mode='w', newline='') as file:
        writer = csv.writer(file)

        all_hidden_states = []
        # Extract representations
        for tgt_lang_code in TGTS:
            if tgt_lang_code != args.src_lang_code:
                print( "Running direction {}-{}".format(args.src_lang_code, tgt_lang_code) )
                with open(args.data, 'r', encoding='utf-8') as f:
                    sentences = [line.strip() for line in f]            
                    for index_sentence, sentence in enumerate(sentences[:MAX_SENTENCES]):
                        sentence = preproc(sentence)
                        input_sentence = '<s> [{}] {} \n[{}]'.format(args.src_lang_code, sentence, tgt_lang_code)
                        hidden_states, input_ids = get_hidden_states(input_sentence, tokenizer, model)
                        input_ids = input_ids.squeeze().tolist()
                        for index_id, id in enumerate(input_ids):
                            last_token = 'yes' if id == input_ids[-1] else 'no'
                            bos = 'yes' if index_id in [0, 1] else 'no'
                            src_tag_token = 'yes' if index_id == 2 else 'no'
                            token_text = tokenizer.decode([id]).replace('\n', '[n]')
                            writer.writerow([index_sentence, id, index_id, args.src_lang_code, tgt_lang_code, bos, src_tag_token, last_token, token_text ])

                        # Assuming hidden_states is a tuple of tensors, one for each layer
                        if not all_hidden_states:  # If all_hidden_states list is empty, initialize it
                           all_hidden_states = [list() for _ in hidden_states]
                        
                        # Append the hidden states of each layer to the corresponding list
                        for layer_index, layer_states in enumerate(hidden_states):
                            hidden_size = layer_states.shape[-1]
                            all_hidden_states[layer_index].append(layer_states.reshape(-1, hidden_size).cpu())

    # Convert and save each layer's hidden states as a NumPy array
    for layer_index, layer_states in enumerate(all_hidden_states):
        # Concatenate the states from all sentences for this layer
        concatenated_hidden_states = torch.cat(layer_states, dim=0)
        # Convert from torch tensor to numpy array
        concatenated_hidden_states_np = concatenated_hidden_states.cpu().numpy()
        #concatenated_hidden_states_np = np.squeeze(concatenated_hidden_states_np, axis=0)
        print(concatenated_hidden_states_np.shape)
        # Define output path
        rep_outpath = os.path.join(args.output_dir, f"layer{layer_index}_reps.npy")
        # Save the numpy array
        np.save(rep_outpath, concatenated_hidden_states_np, allow_pickle=False)
        print(f"Saved representations to {rep_outpath}.")
        get_subspace( concatenated_hidden_states_np, args.output_dir, layer_index )
    
if __name__ == "__main__":
    parser = create_parser()
    args = parser.parse_args()
    main(args)